{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea0cfa44-e395-43fb-a1c6-dc9aee18066c",
   "metadata": {},
   "source": [
    "Read and import all datasets \n",
    "In this chapter we are going to import and clean the datasets needed for this project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1a9d2e-5618-48e3-b492-0cc66f98f69d",
   "metadata": {},
   "source": [
    "The dataset was gotten nigerian university which records or have a detailed information about network traffic data, average_transmit_bmp, average_recieve_bmp\n",
    "date time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d796a3b6-56ae-4d45-9319-4abaa3e64236",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # this libary or module allows me to have acess to my filesystem\n",
    "import pandas as pd #dataframe liabray \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2865712b-a2ce-4a97-8a43-60d0565bf752",
   "metadata": {},
   "source": [
    "# The read_and_merge_xlsx_files function allows us loop through the file directiory where we have all the individual raw dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d617a0-2642-44d2-b973-b07919167e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_merge_xlsx_files(directory):\n",
    "    # Initialize an empty list to store the dataframes\n",
    "    dataframes = []\n",
    "    files = []\n",
    "    # Loop through all the files in the directory\n",
    "    for file_name in os.listdir(directory):\n",
    "        print(file_name)\n",
    "        # Check if the file is an .xlsx file\n",
    "        if file_name.endswith('.xlsx'):\n",
    "            # Construct the full file path\n",
    "            file_path = os.path.join(directory, file_name)\n",
    "            xls = pd.ExcelFile(file_path)\n",
    "            # Read the Excel file\n",
    "            if 'ChartData' in xls.sheet_names:\n",
    "                df = pd.read_excel(xls, sheet_name='ChartData', skiprows=3)\n",
    "            else:\n",
    "                # Load the first sheet as a fallback\n",
    "                df = pd.read_excel(xls, sheet_name=xls.sheet_names[0], skiprows=3)\n",
    "            # df = pd.read_excel(file_path, sheet_name='ChartData', skiprows=3)\n",
    "            # Append the dataframe to the list\n",
    "            dataframes.append(df)\n",
    "           \n",
    "            files.append(file_name)\n",
    "            print('done')\n",
    "    \n",
    "    # Merge all dataframes in the list into a single dataframe\n",
    "    merged_df = pd.concat(dataframes, ignore_index=True)\n",
    "    \n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a72615-9087-4d22-86b1-a81504fbffd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = './raw_datasets'\n",
    "raw_data = read_and_merge_xlsx_files(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3a08fd-1a18-48ce-bf12-1c3c52a54250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename colunms\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c04e470-95f9-412f-9eec-dd9d8bb22d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select Important Columns\n",
    "df = raw_data[['DATE / TIME', 'Unnamed: 1',\n",
    "      'Average Receive bps INTERNET-EDGE-ROUTER - GigabitEthernet0/2.1 · Connection-GLO-2STM-Circuit',\n",
    "      'Average Transmit bps INTERNET-EDGE-ROUTER - GigabitEthernet0/2.1 · Connection-GLO-2STM-Circuit']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88600911-0ff1-478b-9dc0-a5727b76a6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns for clarity\n",
    "df.columns = ['Date', 'Time', 'Average_Receive_bps', 'Average_Transmit_bps']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324660c8-6df9-4820-abea-1884a4f17deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop any rows where all data is NaN\n",
    "df = df.dropna(how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44497b7e-75dc-4c01-a480-b7ce0df28322",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a02987f-5f3e-4751-910f-5a68ea9f258b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all row where date and time is null\n",
    "df = df.dropna(subset=['Date', 'Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070a9d26-b6a4-4645-85e9-c847ce4af758",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d1f59e-a073-4899-b536-e1d266adf85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Date and Time to string before concatenating\n",
    "df['Datetime'] = pd.to_datetime(df['Date'].astype(str) + ' ' + df['Time'].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88268ab-1f05-4049-b8dd-43f42052b85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorder the date for better understanding\n",
    "cleaned_data = df[['Datetime', 'Average_Receive_bps', 'Average_Transmit_bps']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94170240-444c-4920-9da9-18600696aa91",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data_filled = cleaned_data.fillna(method='ffill')\n",
    "cleaned_data_filled.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52858d9-47f5-4fb9-a4fe-3b811841b8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data_filled.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5907d7d8-d93f-4a62-bd02-dd0d84e760e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_duplicated_rows = cleaned_data_filled.duplicated().sum()\n",
    "print(f\"Total duplicated rows: {total_duplicated_rows}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90671b1d-eaed-43f2-aaee-c7f64f1eda56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicates in place without creating a new DataFrame:\n",
    "cleaned_data_filled.drop_duplicates(inplace=True)\n",
    "print(\"Duplicated rows have been removed.\")\n",
    "print(cleaned_data_filled.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cee2542-7ca9-48a4-af97-639356409b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data_filled.to_csv('./datasets/cleaned_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4f962a-47ff-497d-b708-f919203bb0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data_filled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5eaf78-08fa-44de-832c-c11a383ffc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling outliers in the dataset (e.g., capping)\n",
    "cap_receive = cleaned_data_filled['Average_Receive_bps'].quantile(0.99)\n",
    "cleaned_data_filled['Average_Receive_bps'] = cleaned_data_filled['Average_Receive_bps'].clip(upper=cap_receive)\n",
    "print(cap_receive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83d3cec-331a-42cf-9e85-a109c01e97b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data_filled['Day'] = cleaned_data_filled['Datetime'].dt.dayofweek\n",
    "cleaned_data_filled['Hour'] = cleaned_data_filled['Datetime'].dt.hour\n",
    "cleaned_data_filled['Minute'] = cleaned_data_filled['Datetime'].dt.minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a388c9-1d2f-466d-96c1-d45a5ced691b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorder the date for better understanding\n",
    "training_data = cleaned_data_filled[['Day', 'Hour', 'Minute','Datetime', 'Average_Receive_bps', 'Average_Transmit_bps']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e49e2b-e8d5-440b-865b-8e959af717bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data_filled.to_csv('./datasets/cleaned_data_wihtout_outliners.csv', index=False)\n",
    "training_data.to_csv('./datasets/final_train_dataset.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
